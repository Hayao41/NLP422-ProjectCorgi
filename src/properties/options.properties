{
    # embedding layer params
    "word_emb_dims": 0,
    "pos_emb_dims": 25,
    "rel_emb_dims": 25,
    "rp_emb_dims": 0,

    # non linear trans
    "context_linear_dim": 50,

    # context encoder
    "use_bi_lstm": True,
    "lstm_num_layers": 1,
    "lstm_hid_dims": 100,

    # tree children chain
    "use_bi_chain": False,
    "chain_num_layers": 1,
    "chain_hid_dims": 100,

    # tree encoder type
    # @Type DRN : Dynamic recursive neural nets
    # @Type HTLstms : Hierarchical Tree LSTMs
    # @direction B2T : bottom up then top down
    # @direction T2B : top down then bottom up
    # @direction T : just top down
    # @direction B : just bottom up
    "use_tree": True,
    "tree_type": "DRN",
    "direction": "B",

    # attention
    "atten_type": "general",

    # optimization
    "train_batch_size": 5,
    "eval_batch_size": 3,
    "epoch": 100,
    "xavier": True,
    "dropout": 0.1,
    "padding": 0,
    "use_cuda": False,
    "cuda_device": "0",
    "optim": "SGD",
    "lr": 0.01,
    "lr_decay": 0.1,
    "weight_decay": 0.01,
    "momentum": 0.8,
    "betas": (0.9, 0.98),
    "eps": 1e-9,
    "loss_reduce": False,
    "down_sample_prop": 20,
    "save_model": True,
    "save_mode": "best",
    "model_path": "../src/model_state/",
    "log_path": "../src/log/",
    "pic_path": "../src/visual/",
    "test_mode": False,


    # data set prop
    "test_prob": True,
    "train_prop": 1,
    "test_prop": 0.3,
    "dev_prop": 0.
}