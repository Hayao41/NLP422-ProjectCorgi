{
    # embedding layer params
    "word_emb_dims": 0,
    "pos_emb_dims": 25,
    "rel_emb_dims": 25,
    "rp_emb_dims": 0,

    # non linear trans
    "context_linear_dim": 50,

    # context encoder
    "use_bi_lstm": True,
    "lstm_num_layers": 1,
    "lstm_hid_dims": 100,

    # tree children chain
    "use_bi_chain": False,
    "chain_num_layers": 1,
    "chain_hid_dims": 100,

    # tree encoder type
    # @Type DRN : Dynamic recursive neural nets
    # @Type HTLstms : Hierarchical Tree LSTMs
    "use_tree": True,
    "tree_type": "DRN",

    # attention
    "atten_type": "general",

    # optimization
    "train_batch_size": 5,
    "eval_batch_size": 3,
    "epoch": 100,
    "xavier": True,
    "dropout": 0.1,
    "padding": 0,
    "use_cuda": False,
    "cuda_device": "1",
    "optim": "SGD",
    "lr": 0.01,
    "lr_decay": 0.1,
    "weight_decay": 0.01,
    "momentum": 0.8,
    "betas": (0.9, 0.98),
    "eps": 1e-9,
    "loss_reduce": False,
    "down_sample_prop": 20,

    # data set prop
    "train_prop": 7,
    "test_prop": 2,
    "dev_prop": 1
}