{
    "word_emb_dims": 0,
    "pos_emb_dims": 30,
    "rel_emb_dims": 30,
    "rp_vocab_size": 20,
    "rp_emb_dims": 0,
    "context_linear_dim": 30,
    "use_bi_lstm": True,
    "lstm_hid_dims": 30,
    "lstm_num_layers": 1,
    "chain_hid_dims": 30,
    "batch_size": 5,
    "xavier": True,
    "dropout": 0.1,
    "padding": 0,
    "use_cuda": False
}